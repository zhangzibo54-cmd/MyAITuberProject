
import chromadb
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.core import Document

from AIclass.events_class.system_events import LogMessageEvent

import asyncio

class MemorySystem:
    def __init__(self, embed_model, system_event_queue, google_drive_db_path="/app/my_ai_memory/chroma_db"):
        #google_drive_db_path æ—¶é•¿æœŸè®°å¿†dbå‚¨å­˜çš„ä½ç½®
        self.db_path = google_drive_db_path

        # embed_model to deal with memory search
        self.embed_model = embed_model

        def init_index():
            db = chromadb.PersistentClient(path=self.db_path)
            chroma_collection = db.get_or_create_collection("long_term_memory")
            #å¤šè¡Œæ•°åˆ—ï¼Œç¬¬ä¸€è¡Œæ˜¯æ–‡æ¡£ï¼Œç¬¬ä¸‰è¡Œæ˜¯å¯¹åº”çš„å‘é‡

            vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
            #ä¸€ä¸ªåŸºäºä¸Šè¿°é›†åˆcollectionçš„ä¹¦æ¶

            storage_context = StorageContext.from_defaults(vector_store=vector_store)
            #ä¹¦æ¶çš„æ³¨å†Œç³»ç»Ÿ
            # åˆ›å»ºå‘é‡ç´¢å¼•ï¼Œè¿™æ˜¯LlamaIndexä¸­æ“ä½œè®°å¿†çš„æ ¸å¿ƒ
            # å¦‚æœæ•°æ®åº“ä¸­å·²æœ‰è®°å¿†ï¼Œå®ƒä¼šè‡ªåŠ¨åŠ è½½

            index = VectorStoreIndex.from_vector_store(
            vector_store,
            embed_model=self.embed_model,
            )

            return index

        self.index = init_index()# å…ˆè®¾ä¸ºNone,embedding_modelä¸‹è½½å¥½ä¹‹åå†æ”¹å›æ¥

        # to log
        self.system_event_queue = system_event_queue

    async def init_and_get_index(self):

        "create vector_store, storage_contex and index, then return index"

        db = chromadb.PersistentClient(path=self.db_path)
        chroma_collection = db.get_or_create_collection("long_term_memory")
        #å¤šè¡Œæ•°åˆ—ï¼Œç¬¬ä¸€è¡Œæ˜¯æ–‡æ¡£ï¼Œç¬¬ä¸‰è¡Œæ˜¯å¯¹åº”çš„å‘é‡

        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
        #ä¸€ä¸ªåŸºäºä¸Šè¿°é›†åˆcollectionçš„ä¹¦æ¶

        storage_context = StorageContext.from_defaults(vector_store=vector_store)
        #ä¹¦æ¶çš„æ³¨å†Œç³»ç»Ÿ
        # åˆ›å»ºå‘é‡ç´¢å¼•ï¼Œè¿™æ˜¯LlamaIndexä¸­æ“ä½œè®°å¿†çš„æ ¸å¿ƒ
        # å¦‚æœæ•°æ®åº“ä¸­å·²æœ‰è®°å¿†ï¼Œå®ƒä¼šè‡ªåŠ¨åŠ è½½


        index = VectorStoreIndex.from_vector_store(
            vector_store,
            embed_model=self.embed_model,
        )
        #sä¹¦æ¶çš„ç®¡ç†å‘˜ï¼Œ  storage_context,indexéƒ½è‡ªåŠ¨å…³è”åˆ°åŒä¸€å¯¹è±¡ï¼Œ
        # å½“indexè¢«è°ƒç”¨ä¿®æ”¹æ—¶storage_ã€‚ã€‚è¢«è‡ªåŠ¨ä¿®æ”¹
        return index

    async def memorize(self, text_to_remember):
        """
        MemorySystemä½œç”¨çš„åœ°æ–¹3/3 

        # å°†æ–°çš„æ–‡æœ¬ä¿¡æ¯å­˜å…¥é•¿æœŸè®°å¿†
        # :param text_to_remember: éœ€è¦è¢«è®°ä½çš„å­—ç¬¦ä¸²
        # """


        # LlamaIndexéœ€è¦å°†æ–‡æœ¬åŒ…è£…æˆDocumentå¯¹è±¡
        document = Document(text=text_to_remember)
        self.index.insert(document)
        print(f"ğŸ§  æ–°è®°å¿†å·²å­˜å…¥: '{text_to_remember}'")

    async def recall(self, query_text, similarity_top_k=3):
        """
        æ ¹æ®æŸ¥è¯¢æ–‡æœ¬ï¼Œä»è®°å¿†ä¸­â€œå›å¿†â€æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚
        :param query_text: ç”¨äºæŸ¥è¯¢çš„æ–‡æœ¬ã€‚
        :param similarity_top_k: è¿”å›æœ€ç›¸ä¼¼ç»“æœçš„æ•°é‡ã€‚
        :return: ç›¸å…³è®°å¿†çš„åˆ—è¡¨ã€‚
        """
        retriever = self.index.as_retriever(similarity_top_k=similarity_top_k)
        nodes = await retriever.aretrieve(query_text)
        
        results = []
        if nodes:
            print(f"ğŸ§  æ ¹æ® '{query_text}' å›å¿†èµ·ä»¥ä¸‹å†…å®¹:")
            for node in nodes:
                results.append({'id': node.node.node_id, 'text': node.node.get_content(), 'score': node.score})
                print(f"   - [ID: {node.node.node_id}, Score: {node.score:.4f}]: {node.node.get_content()}")
        else:
            print(f"ğŸ§  å¯¹äº '{query_text}'ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®°å¿†ã€‚")
            
        return results

    async def list_all_memories(self):
        """
        ã€æŸ¥çœ‹åŠŸèƒ½ã€‘åˆ—å‡ºæ•°æ®åº“ä¸­æ‰€æœ‰å·²å­˜å‚¨çš„è®°å¿†ã€‚
        ç›´æ¥ä»ChromaDBé›†åˆä¸­è·å–æ•°æ®ã€‚
        """
        print("\n--- ğŸ“– æŸ¥çœ‹æ‰€æœ‰è®°å¿† ---")
        memories = self.chroma_collection.get()
        if not memories['ids']:
            print("   è®°å¿†åº“ä¸ºç©ºã€‚")
            return None
            
        for i, doc_id in enumerate(memories['ids']):
            text = memories['documents'][i]
            metadata = memories['metadatas'][i]
            print(f" - ID: {doc_id}")
            print(f"   å†…å®¹: {text}")
            print(f"   å…ƒæ•°æ®: {metadata}")
            print("-" * 10)
        return memories  

    async def forget(self, memory_id):
        """
        ã€åˆ é™¤åŠŸèƒ½ã€‘æ ¹æ®æä¾›çš„IDä»è®°å¿†åº“ä¸­åˆ é™¤ä¸€æ¡è®°å¿†ã€‚
        :param memory_id: è¦åˆ é™¤çš„è®°å¿†çš„å”¯ä¸€ID (å¯ä»¥é€šè¿‡ list_all_memories è·å–)ã€‚
        """
        try:
            # ç›´æ¥æ“ä½œChromaDBé›†åˆè¿›è¡Œåˆ é™¤
            self.chroma_collection.delete(ids=[memory_id])
            # æ³¨æ„ï¼šLlamaIndexçš„ç´¢å¼•å¯èƒ½éœ€è¦é‡å»ºæˆ–æ›´æ–°æ‰èƒ½å®Œå…¨åŒæ­¥çŠ¶æ€ï¼Œ
            # ä½†å¯¹äºChromaDBåç«¯ï¼Œç›´æ¥åˆ é™¤é€šå¸¸æ˜¯æœ‰æ•ˆçš„ã€‚
            print(f"ğŸ—‘ï¸ è®°å¿†å·²åˆ é™¤ (ID: {memory_id})")
            print(f"ğŸ—‘ï¸ è®°å¿†å·²åˆ é™¤ (ID: {memory_id})")
        except Exception as e:
            error_msg = f"åˆ é™¤è®°å¿† (ID: {memory_id}) æ—¶å‡ºé”™: {e}"
            print(error_msg)

if __name__ == "__main__":
    from llama_index.embeddings.ollama import OllamaEmbedding
    from llama_index.llms.ollama import Ollama
    
    embed_model = OllamaEmbedding(model_name="bge-m3", base_url="http://localhost:11434")##
    system_event_queue = asyncio.Queue()
    ai_memory = MemorySystem(embed_model=embed_model, system_event_queue=system_event_queue)
    asyncio.run(ai_memory.memorize("åˆéŸ³æœªæ¥åˆå«mikuï¼Œæ˜¯æ—¥æœ¬è‘—åçš„è™šæ‹Ÿæ­Œå§¬"))
    asyncio.run(ai_memory.memorize("åˆéŸ³æœªæ¥åˆå«mikuï¼Œæ˜¯æ—¥æœ¬è‘—åçš„è™šæ‹Ÿæ­Œå§¬"))
    





